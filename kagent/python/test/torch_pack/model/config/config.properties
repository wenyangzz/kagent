inference_address=http://0.0.0.0:8085
management_address=http://0.0.0.0:8085
metrics_address=http://0.0.0.0:8082
grpc_inference_port=9000
grpc_management_port=7071
load_models=loading-prediction.mar
enable_metrics_api=true
metrics_format=prometheus
number_of_netty_threads=4
job_queue_size=10
# 必需参数service_envelope
service_envelope=kserve
enable_envvars_config=false
install_py_dep_per_model=true
model_store=/mnt/models/model-store
model_snapshot={"name":"startup.cfg","modelCount":1,"models":{"loading-prediction":{"1.0":{"defaultVersion":true,"marName":"loading-prediction.mar","minWorkers":1,"maxWorkers":5,"batchSize":10,"maxBatchDelay":10,"responseTimeout":120}}}}
