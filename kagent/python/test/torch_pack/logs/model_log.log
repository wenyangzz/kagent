2022-11-01T10:50:18,625 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T10:50:18,626 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]21582
2022-11-01T10:50:18,627 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T10:50:18,627 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T10:50:18,637 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T10:50:18,678 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T10:50:18,682 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend worker process died.
2022-11-01T10:50:18,683 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T10:50:18,683 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG - /root/tensorflow-env/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
2022-11-01T10:50:18,683 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 210, in <module>
2022-11-01T10:50:18,683 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     worker.run_server()
2022-11-01T10:50:18,684 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG -   warnings.warn(msg)
2022-11-01T10:50:18,684 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 181, in run_server
2022-11-01T10:50:18,684 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-11-01T10:50:18,684 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 139, in handle_connection
2022-11-01T10:50:18,684 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-11-01T10:50:18,684 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 111, in load_model
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     limit_max_image_pixels,
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_loader.py", line 151, in load
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 84, in initialize
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     model_dir, model_file, model_pt_path)
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 143, in _load_pickled_model
2022-11-01T10:50:18,685 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     model_class_definitions
2022-11-01T10:50:18,686 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - ValueError: Expected only one class as model definition. [<class 'model.Chomp1d'>, <class 'model.TCN'>, <class 'model.TemporalBlock'>, <class 'model.TemporalConvNet'>]
2022-11-01T10:58:05,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T10:58:05,968 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]22095
2022-11-01T10:58:05,968 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T10:58:05,968 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T10:58:05,978 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T10:58:05,995 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T10:58:05,999 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend worker process died.
2022-11-01T10:58:06,000 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T10:58:06,000 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 210, in <module>
2022-11-01T10:58:06,000 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     worker.run_server()
2022-11-01T10:58:06,000 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG - /root/tensorflow-env/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
2022-11-01T10:58:06,000 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 181, in run_server
2022-11-01T10:58:06,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-11-01T10:58:06,001 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG -   warnings.warn(msg)
2022-11-01T10:58:06,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 139, in handle_connection
2022-11-01T10:58:06,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-11-01T10:58:06,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 111, in load_model
2022-11-01T10:58:06,002 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     limit_max_image_pixels,
2022-11-01T10:58:06,002 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_loader.py", line 151, in load
2022-11-01T10:58:06,002 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-11-01T10:58:06,003 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 84, in initialize
2022-11-01T10:58:06,003 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     model_dir, model_file, model_pt_path)
2022-11-01T10:58:06,003 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 143, in _load_pickled_model
2022-11-01T10:58:06,003 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     model_class_definitions
2022-11-01T10:58:06,004 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - ValueError: Expected only one class as model definition. [<class 'model.Chomp1d'>, <class 'model.TCN'>, <class 'model.TemporalBlock'>, <class 'model.TemporalConvNet'>]
2022-11-01T10:59:17,064 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T10:59:17,065 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]22250
2022-11-01T10:59:17,066 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T10:59:17,066 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T10:59:17,076 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T10:59:17,097 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T10:59:17,101 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend worker process died.
2022-11-01T10:59:17,102 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T10:59:17,102 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 210, in <module>
2022-11-01T10:59:17,103 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     worker.run_server()
2022-11-01T10:59:17,102 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG - /root/tensorflow-env/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
2022-11-01T10:59:17,103 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 181, in run_server
2022-11-01T10:59:17,103 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-11-01T10:59:17,103 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG -   warnings.warn(msg)
2022-11-01T10:59:17,103 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 139, in handle_connection
2022-11-01T10:59:17,104 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-11-01T10:59:17,104 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 111, in load_model
2022-11-01T10:59:17,104 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     limit_max_image_pixels,
2022-11-01T10:59:17,104 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_loader.py", line 151, in load
2022-11-01T10:59:17,104 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-11-01T10:59:17,105 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 84, in initialize
2022-11-01T10:59:17,105 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     model_dir, model_file, model_pt_path)
2022-11-01T10:59:17,105 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 148, in _load_pickled_model
2022-11-01T10:59:17,105 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     model = model_class()
2022-11-01T10:59:17,105 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - TypeError: __init__() missing 5 required positional arguments: 'input_size', 'output_size', 'num_channels', 'kernel_size', and 'dropout'
2022-11-01T11:07:42,352 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T11:07:42,354 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]22766
2022-11-01T11:07:42,354 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T11:07:42,354 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T11:07:42,363 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T11:07:42,378 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T11:07:42,388 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend worker process died.
2022-11-01T11:07:42,388 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T11:07:42,389 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 210, in <module>
2022-11-01T11:07:42,389 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG - /root/tensorflow-env/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
2022-11-01T11:07:42,389 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     worker.run_server()
2022-11-01T11:07:42,389 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 181, in run_server
2022-11-01T11:07:42,390 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-11-01T11:07:42,390 [WARN ] W-9000-loading-prediction_1.0-stderr MODEL_LOG -   warnings.warn(msg)
2022-11-01T11:07:42,390 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 139, in handle_connection
2022-11-01T11:07:42,390 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-11-01T11:07:42,390 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_service_worker.py", line 111, in load_model
2022-11-01T11:07:42,390 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     limit_max_image_pixels,
2022-11-01T11:07:42,391 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/model_loader.py", line 151, in load
2022-11-01T11:07:42,391 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-11-01T11:07:42,391 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 91, in initialize
2022-11-01T11:07:42,391 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-11-01T11:07:42,391 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 115, in _load_torchscript_model
2022-11-01T11:07:42,392 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-11-01T11:07:42,392 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/torch/jit/_serialization.py", line 161, in load
2022-11-01T11:07:42,392 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)
2022-11-01T11:07:42,392 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: PytorchStreamReader failed locating file constants.pkl: file not found
2022-11-01T11:22:13,408 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T11:22:13,409 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]23594
2022-11-01T11:22:13,410 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T11:22:13,410 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T11:22:13,420 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T11:22:13,436 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T11:22:13,478 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T16:16:40,181 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T16:16:40,182 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]38860
2022-11-01T16:16:40,183 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T16:16:40,183 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T16:16:40,192 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T16:16:40,206 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T16:16:40,245 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T16:18:16,964 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667290696
2022-11-01T16:18:16,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:18:16,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:18:16,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:18:16,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:18:16,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:18:16,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:18:16,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 165, in preprocess
2022-11-01T16:18:16,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(data, device=self.device)
2022-11-01T16:18:16,968 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: Could not infer dtype of dict
2022-11-01T16:20:00,931 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667290800
2022-11-01T16:20:00,932 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:20:00,932 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:20:00,932 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:20:00,933 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:20:00,933 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:20:00,933 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:20:00,933 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 165, in preprocess
2022-11-01T16:20:00,933 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(data, device=self.device)
2022-11-01T16:20:00,933 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: Could not infer dtype of dict
2022-11-01T16:20:32,999 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667290832
2022-11-01T16:20:33,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:20:33,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:20:33,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:20:33,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:20:33,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:20:33,001 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:20:33,002 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 165, in preprocess
2022-11-01T16:20:33,002 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(data, device=self.device)
2022-11-01T16:20:33,002 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: Could not infer dtype of dict
2022-11-01T16:37:40,364 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667291860
2022-11-01T16:37:40,366 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:37:40,366 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:37:40,366 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:37:40,366 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:37:40,366 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:37:40,367 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:37:40,367 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 165, in preprocess
2022-11-01T16:37:40,367 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(data, device=self.device)
2022-11-01T16:37:40,367 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: Could not infer dtype of dict
2022-11-01T16:44:01,790 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T16:44:01,791 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]40502
2022-11-01T16:44:01,791 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T16:44:01,791 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T16:44:01,801 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T16:44:01,817 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T16:44:01,856 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T16:44:12,331 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667292252
2022-11-01T16:44:12,334 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [{'body': [[[0.027652508954327904, 0.07238308265169527, 0.09864100395351688, 0.04425131509070399, 0.10793293031718294, 0.07389489307156828, 0.12064058423390212, 0.10187934183235252, 0.09341338949880844, 0.09527291863890545, 0.11822001940163833, 0.06415241774520729, 0.15985844033815738, 0.11248141394752291, 0.1075329862755908, 0.09917514315152125, 0.0818321139053955, 0.07239242430455653, 0.09363908460114258, 0.09836124685343056, 0.10574652454025393, 0.09890158523453704, 0.1526130124328318, 0.18719417731209193, 0.1885288047673577, 0.2261635980308232, 0.20786397945701818, 0.22838564967365854, 0.2255767041061822, 0.6137741860819624, 0.2010166356838014, 0.19345743860500403, 0.2037928853750772, 0.21149949796603382, 0.21474549163374973, 0.21787418281909796, 0.22443279357227164, 0.23782154771927536, 0.22467722336698673, 0.23225774100925323, 0.21204969043306857, 0.24363216673089402, 0.22757264661049215, 0.24997438878271716, 0.22984207126554634, 0.21612404691331488, 0.1954175423487311, 0.1470415511939073, 0.15017012637066354, 0.1282514113355846, 0.1600614562644808, 0.1954663974857656, 0.17255251210146152, 0.20583605379259814, 0.2022914616319765, 0.20896027369600179, 0.19472840856970897, 0.20303572560854818, 0.22362215012457645, 0.20771741296902121, 0.5625202893457166, 0.2255601393604278, 0.24650449948174763, 0.23919865832066547, 0.5842179092973283, 0.2535873789573413, 0.2534568779067799, 0.2457886644407459, 0.23949227935838685, 0.2510887644876215, 0.28886937492785214, 0.28636650322901824, 0.6726774679616399, 0.22696724726912332, 0.2111760995050743, 0.21229407064273903, 0.18612568449362893, 0.21008112690358186, 0.19068567873679085, 0.1751503401791556, 0.08944879709338445, 0.1097361187676429, 0.07699696987634731, 0.1368366355997489, 0.11287362751902351, 0.09091659907469825, 0.06589933582690254, 0.10360271952187153, 0.09765765328270329, 0.08350698932606214, 0.08663845849211646, 0.08560970897039663, 0.0818726482528911, 0.111095863369841, 0.10451426797720198, 0.091473974511811]], [[0.07108073214347084, 0.07855894518070233, 0.06871803347355863, 0.08053185008856067, 0.1462422795668576, 0.10377282358329833, 0.1375701632822184, 0.10965704229061109, 0.1793861461304077, 0.14193757128124643, 0.15430233928118328, 0.15774236617157142, 0.13547264511396734, 0.15580052199397382, 0.1077183006873966, 0.1476057013629621, 0.14801538304716075, 0.12830803214354036, 0.12468708885967782, 0.10896787178130425, 0.13627592006767075, 0.15156159297350683, 0.10579636244010451, 0.11813957172472592, 0.18893022865020964, 0.1979769982583465, 0.1325203730388171, 0.2182043335679129, 0.18524094886471942, 0.6143401280633585, 0.23855537395243484, 0.16313244819394923, 0.16088954645777656, 0.20024043891853513, 0.1959589414394306, 0.1578944390827772, 0.17027686107494994, 0.17803893888120773, 0.17338886817260743, 0.1984508200003811, 0.18517650347651377, 0.20541136893756534, 0.1850774397290474, 0.19477368285486088, 0.1659294503092899, 0.16635080536062455, 0.14417044218129288, 0.12884640912974046, 0.11512213543200275, 0.0853890998645376, 0.08749685076376013, 0.1469138822547218, 0.11635817283059051, 0.1668843599837598, 0.15482450214870982, 0.19738357353674774, 0.17124986554583446, 0.16253388654055692, 0.18336561288093003, 0.15788268244817885, 0.5286078827449375, 0.189298569680485, 0.19339474190412873, 0.18630948192430793, 0.5504771065455623, 0.18091753061482727, 0.22806193511390044, 0.19645263004975122, 0.199818382641865, 0.253321267114035, 0.30304718541136194, 0.26228270583167207, 0.6589699709085498, 0.20542577913085278, 0.1904728331471315, 0.14779533838920358, 0.18164114427396158, 0.17409439651117384, 0.09565996673792566, 0.13812939257401974, 0.0932176198326777, 0.10944649619562609, 0.06365877624419974, 0.09266602679154831, 0.07515209741831146, 0.035529825533945604, 0.06567972260648676, 0.053655801312592594, 0.058493008804908424, 0.06400640696957396, 0.10486689176410674, 0.040831139183156194, 0.024881588381710163, 0.08073079976956364, 0.039142647377853695, 0.11545730583288337]]]}]
2022-11-01T16:44:12,335 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:44:12,335 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:44:12,335 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:44:12,335 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:44:12,335 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:44:12,336 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:44:12,336 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/tmp/models/6d4377416f414975ba97e95fb014d483/my_handler.py", line 15, in preprocess
2022-11-01T16:44:12,336 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(data, device=self.device)
2022-11-01T16:44:12,336 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: Could not infer dtype of dict
2022-11-01T16:47:25,745 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667292445
2022-11-01T16:47:25,746 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [{'body': {'instances': [[[0.027652508954327904, 0.07238308265169527, 0.09864100395351688, 0.04425131509070399, 0.10793293031718294, 0.07389489307156828, 0.12064058423390212, 0.10187934183235252, 0.09341338949880844, 0.09527291863890545, 0.11822001940163833, 0.06415241774520729, 0.15985844033815738, 0.11248141394752291, 0.1075329862755908, 0.09917514315152125, 0.0818321139053955, 0.07239242430455653, 0.09363908460114258, 0.09836124685343056, 0.10574652454025393, 0.09890158523453704, 0.1526130124328318, 0.18719417731209193, 0.1885288047673577, 0.2261635980308232, 0.20786397945701818, 0.22838564967365854, 0.2255767041061822, 0.6137741860819624, 0.2010166356838014, 0.19345743860500403, 0.2037928853750772, 0.21149949796603382, 0.21474549163374973, 0.21787418281909796, 0.22443279357227164, 0.23782154771927536, 0.22467722336698673, 0.23225774100925323, 0.21204969043306857, 0.24363216673089402, 0.22757264661049215, 0.24997438878271716, 0.22984207126554634, 0.21612404691331488, 0.1954175423487311, 0.1470415511939073, 0.15017012637066354, 0.1282514113355846, 0.1600614562644808, 0.1954663974857656, 0.17255251210146152, 0.20583605379259814, 0.2022914616319765, 0.20896027369600179, 0.19472840856970897, 0.20303572560854818, 0.22362215012457645, 0.20771741296902121, 0.5625202893457166, 0.2255601393604278, 0.24650449948174763, 0.23919865832066547, 0.5842179092973283, 0.2535873789573413, 0.2534568779067799, 0.2457886644407459, 0.23949227935838685, 0.2510887644876215, 0.28886937492785214, 0.28636650322901824, 0.6726774679616399, 0.22696724726912332, 0.2111760995050743, 0.21229407064273903, 0.18612568449362893, 0.21008112690358186, 0.19068567873679085, 0.1751503401791556, 0.08944879709338445, 0.1097361187676429, 0.07699696987634731, 0.1368366355997489, 0.11287362751902351, 0.09091659907469825, 0.06589933582690254, 0.10360271952187153, 0.09765765328270329, 0.08350698932606214, 0.08663845849211646, 0.08560970897039663, 0.0818726482528911, 0.111095863369841, 0.10451426797720198, 0.091473974511811]], [[0.07108073214347084, 0.07855894518070233, 0.06871803347355863, 0.08053185008856067, 0.1462422795668576, 0.10377282358329833, 0.1375701632822184, 0.10965704229061109, 0.1793861461304077, 0.14193757128124643, 0.15430233928118328, 0.15774236617157142, 0.13547264511396734, 0.15580052199397382, 0.1077183006873966, 0.1476057013629621, 0.14801538304716075, 0.12830803214354036, 0.12468708885967782, 0.10896787178130425, 0.13627592006767075, 0.15156159297350683, 0.10579636244010451, 0.11813957172472592, 0.18893022865020964, 0.1979769982583465, 0.1325203730388171, 0.2182043335679129, 0.18524094886471942, 0.6143401280633585, 0.23855537395243484, 0.16313244819394923, 0.16088954645777656, 0.20024043891853513, 0.1959589414394306, 0.1578944390827772, 0.17027686107494994, 0.17803893888120773, 0.17338886817260743, 0.1984508200003811, 0.18517650347651377, 0.20541136893756534, 0.1850774397290474, 0.19477368285486088, 0.1659294503092899, 0.16635080536062455, 0.14417044218129288, 0.12884640912974046, 0.11512213543200275, 0.0853890998645376, 0.08749685076376013, 0.1469138822547218, 0.11635817283059051, 0.1668843599837598, 0.15482450214870982, 0.19738357353674774, 0.17124986554583446, 0.16253388654055692, 0.18336561288093003, 0.15788268244817885, 0.5286078827449375, 0.189298569680485, 0.19339474190412873, 0.18630948192430793, 0.5504771065455623, 0.18091753061482727, 0.22806193511390044, 0.19645263004975122, 0.199818382641865, 0.253321267114035, 0.30304718541136194, 0.26228270583167207, 0.6589699709085498, 0.20542577913085278, 0.1904728331471315, 0.14779533838920358, 0.18164114427396158, 0.17409439651117384, 0.09565996673792566, 0.13812939257401974, 0.0932176198326777, 0.10944649619562609, 0.06365877624419974, 0.09266602679154831, 0.07515209741831146, 0.035529825533945604, 0.06567972260648676, 0.053655801312592594, 0.058493008804908424, 0.06400640696957396, 0.10486689176410674, 0.040831139183156194, 0.024881588381710163, 0.08073079976956364, 0.039142647377853695, 0.11545730583288337]]]}}]
2022-11-01T16:47:25,747 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:47:25,747 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:47:25,747 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:47:25,747 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:47:25,747 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:47:25,748 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:47:25,748 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/tmp/models/6d4377416f414975ba97e95fb014d483/my_handler.py", line 15, in preprocess
2022-11-01T16:47:25,748 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(data, device=self.device)
2022-11-01T16:47:25,748 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - RuntimeError: Could not infer dtype of dict
2022-11-01T16:54:49,558 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T16:54:49,559 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]41175
2022-11-01T16:54:49,559 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T16:54:49,560 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T16:54:49,570 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T16:54:49,585 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T16:54:49,626 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T16:54:55,959 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667292895
2022-11-01T16:54:55,965 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [{'body': {'instances': [[[0.027652508954327904, 0.07238308265169527, 0.09864100395351688, 0.04425131509070399, 0.10793293031718294, 0.07389489307156828, 0.12064058423390212, 0.10187934183235252, 0.09341338949880844, 0.09527291863890545, 0.11822001940163833, 0.06415241774520729, 0.15985844033815738, 0.11248141394752291, 0.1075329862755908, 0.09917514315152125, 0.0818321139053955, 0.07239242430455653, 0.09363908460114258, 0.09836124685343056, 0.10574652454025393, 0.09890158523453704, 0.1526130124328318, 0.18719417731209193, 0.1885288047673577, 0.2261635980308232, 0.20786397945701818, 0.22838564967365854, 0.2255767041061822, 0.6137741860819624, 0.2010166356838014, 0.19345743860500403, 0.2037928853750772, 0.21149949796603382, 0.21474549163374973, 0.21787418281909796, 0.22443279357227164, 0.23782154771927536, 0.22467722336698673, 0.23225774100925323, 0.21204969043306857, 0.24363216673089402, 0.22757264661049215, 0.24997438878271716, 0.22984207126554634, 0.21612404691331488, 0.1954175423487311, 0.1470415511939073, 0.15017012637066354, 0.1282514113355846, 0.1600614562644808, 0.1954663974857656, 0.17255251210146152, 0.20583605379259814, 0.2022914616319765, 0.20896027369600179, 0.19472840856970897, 0.20303572560854818, 0.22362215012457645, 0.20771741296902121, 0.5625202893457166, 0.2255601393604278, 0.24650449948174763, 0.23919865832066547, 0.5842179092973283, 0.2535873789573413, 0.2534568779067799, 0.2457886644407459, 0.23949227935838685, 0.2510887644876215, 0.28886937492785214, 0.28636650322901824, 0.6726774679616399, 0.22696724726912332, 0.2111760995050743, 0.21229407064273903, 0.18612568449362893, 0.21008112690358186, 0.19068567873679085, 0.1751503401791556, 0.08944879709338445, 0.1097361187676429, 0.07699696987634731, 0.1368366355997489, 0.11287362751902351, 0.09091659907469825, 0.06589933582690254, 0.10360271952187153, 0.09765765328270329, 0.08350698932606214, 0.08663845849211646, 0.08560970897039663, 0.0818726482528911, 0.111095863369841, 0.10451426797720198, 0.091473974511811]], [[0.07108073214347084, 0.07855894518070233, 0.06871803347355863, 0.08053185008856067, 0.1462422795668576, 0.10377282358329833, 0.1375701632822184, 0.10965704229061109, 0.1793861461304077, 0.14193757128124643, 0.15430233928118328, 0.15774236617157142, 0.13547264511396734, 0.15580052199397382, 0.1077183006873966, 0.1476057013629621, 0.14801538304716075, 0.12830803214354036, 0.12468708885967782, 0.10896787178130425, 0.13627592006767075, 0.15156159297350683, 0.10579636244010451, 0.11813957172472592, 0.18893022865020964, 0.1979769982583465, 0.1325203730388171, 0.2182043335679129, 0.18524094886471942, 0.6143401280633585, 0.23855537395243484, 0.16313244819394923, 0.16088954645777656, 0.20024043891853513, 0.1959589414394306, 0.1578944390827772, 0.17027686107494994, 0.17803893888120773, 0.17338886817260743, 0.1984508200003811, 0.18517650347651377, 0.20541136893756534, 0.1850774397290474, 0.19477368285486088, 0.1659294503092899, 0.16635080536062455, 0.14417044218129288, 0.12884640912974046, 0.11512213543200275, 0.0853890998645376, 0.08749685076376013, 0.1469138822547218, 0.11635817283059051, 0.1668843599837598, 0.15482450214870982, 0.19738357353674774, 0.17124986554583446, 0.16253388654055692, 0.18336561288093003, 0.15788268244817885, 0.5286078827449375, 0.189298569680485, 0.19339474190412873, 0.18630948192430793, 0.5504771065455623, 0.18091753061482727, 0.22806193511390044, 0.19645263004975122, 0.199818382641865, 0.253321267114035, 0.30304718541136194, 0.26228270583167207, 0.6589699709085498, 0.20542577913085278, 0.1904728331471315, 0.14779533838920358, 0.18164114427396158, 0.17409439651117384, 0.09565996673792566, 0.13812939257401974, 0.0932176198326777, 0.10944649619562609, 0.06365877624419974, 0.09266602679154831, 0.07515209741831146, 0.035529825533945604, 0.06567972260648676, 0.053655801312592594, 0.058493008804908424, 0.06400640696957396, 0.10486689176410674, 0.040831139183156194, 0.024881588381710163, 0.08073079976956364, 0.039142647377853695, 0.11545730583288337]]]}}]
2022-11-01T16:54:55,965 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:54:55,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:54:55,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:54:55,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:54:55,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:54:55,966 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:54:55,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/tmp/models/714535851e9d4eeb849bf10fd6cfb0cb/my_handler.py", line 19, in preprocess
2022-11-01T16:54:55,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data = data['body']['instance']
2022-11-01T16:54:55,967 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - KeyError: 'instance'
2022-11-01T16:55:45,996 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T16:55:45,997 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]41339
2022-11-01T16:55:45,997 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T16:55:45,998 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T16:55:46,007 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T16:55:46,022 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T16:55:46,062 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T16:55:54,934 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667292954
2022-11-01T16:55:54,939 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [{'body': {'instances': [[[0.027652508954327904, 0.07238308265169527, 0.09864100395351688, 0.04425131509070399, 0.10793293031718294, 0.07389489307156828, 0.12064058423390212, 0.10187934183235252, 0.09341338949880844, 0.09527291863890545, 0.11822001940163833, 0.06415241774520729, 0.15985844033815738, 0.11248141394752291, 0.1075329862755908, 0.09917514315152125, 0.0818321139053955, 0.07239242430455653, 0.09363908460114258, 0.09836124685343056, 0.10574652454025393, 0.09890158523453704, 0.1526130124328318, 0.18719417731209193, 0.1885288047673577, 0.2261635980308232, 0.20786397945701818, 0.22838564967365854, 0.2255767041061822, 0.6137741860819624, 0.2010166356838014, 0.19345743860500403, 0.2037928853750772, 0.21149949796603382, 0.21474549163374973, 0.21787418281909796, 0.22443279357227164, 0.23782154771927536, 0.22467722336698673, 0.23225774100925323, 0.21204969043306857, 0.24363216673089402, 0.22757264661049215, 0.24997438878271716, 0.22984207126554634, 0.21612404691331488, 0.1954175423487311, 0.1470415511939073, 0.15017012637066354, 0.1282514113355846, 0.1600614562644808, 0.1954663974857656, 0.17255251210146152, 0.20583605379259814, 0.2022914616319765, 0.20896027369600179, 0.19472840856970897, 0.20303572560854818, 0.22362215012457645, 0.20771741296902121, 0.5625202893457166, 0.2255601393604278, 0.24650449948174763, 0.23919865832066547, 0.5842179092973283, 0.2535873789573413, 0.2534568779067799, 0.2457886644407459, 0.23949227935838685, 0.2510887644876215, 0.28886937492785214, 0.28636650322901824, 0.6726774679616399, 0.22696724726912332, 0.2111760995050743, 0.21229407064273903, 0.18612568449362893, 0.21008112690358186, 0.19068567873679085, 0.1751503401791556, 0.08944879709338445, 0.1097361187676429, 0.07699696987634731, 0.1368366355997489, 0.11287362751902351, 0.09091659907469825, 0.06589933582690254, 0.10360271952187153, 0.09765765328270329, 0.08350698932606214, 0.08663845849211646, 0.08560970897039663, 0.0818726482528911, 0.111095863369841, 0.10451426797720198, 0.091473974511811]], [[0.07108073214347084, 0.07855894518070233, 0.06871803347355863, 0.08053185008856067, 0.1462422795668576, 0.10377282358329833, 0.1375701632822184, 0.10965704229061109, 0.1793861461304077, 0.14193757128124643, 0.15430233928118328, 0.15774236617157142, 0.13547264511396734, 0.15580052199397382, 0.1077183006873966, 0.1476057013629621, 0.14801538304716075, 0.12830803214354036, 0.12468708885967782, 0.10896787178130425, 0.13627592006767075, 0.15156159297350683, 0.10579636244010451, 0.11813957172472592, 0.18893022865020964, 0.1979769982583465, 0.1325203730388171, 0.2182043335679129, 0.18524094886471942, 0.6143401280633585, 0.23855537395243484, 0.16313244819394923, 0.16088954645777656, 0.20024043891853513, 0.1959589414394306, 0.1578944390827772, 0.17027686107494994, 0.17803893888120773, 0.17338886817260743, 0.1984508200003811, 0.18517650347651377, 0.20541136893756534, 0.1850774397290474, 0.19477368285486088, 0.1659294503092899, 0.16635080536062455, 0.14417044218129288, 0.12884640912974046, 0.11512213543200275, 0.0853890998645376, 0.08749685076376013, 0.1469138822547218, 0.11635817283059051, 0.1668843599837598, 0.15482450214870982, 0.19738357353674774, 0.17124986554583446, 0.16253388654055692, 0.18336561288093003, 0.15788268244817885, 0.5286078827449375, 0.189298569680485, 0.19339474190412873, 0.18630948192430793, 0.5504771065455623, 0.18091753061482727, 0.22806193511390044, 0.19645263004975122, 0.199818382641865, 0.253321267114035, 0.30304718541136194, 0.26228270583167207, 0.6589699709085498, 0.20542577913085278, 0.1904728331471315, 0.14779533838920358, 0.18164114427396158, 0.17409439651117384, 0.09565996673792566, 0.13812939257401974, 0.0932176198326777, 0.10944649619562609, 0.06365877624419974, 0.09266602679154831, 0.07515209741831146, 0.035529825533945604, 0.06567972260648676, 0.053655801312592594, 0.058493008804908424, 0.06400640696957396, 0.10486689176410674, 0.040831139183156194, 0.024881588381710163, 0.08073079976956364, 0.039142647377853695, 0.11545730583288337]]]}}]
2022-11-01T16:55:54,939 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/service.py", line 102, in predict
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/root/tensorflow-env/lib/python3.6/site-packages/ts/torch_handler/base_handler.py", line 229, in handle
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -   File "/tmp/models/08c4cd966c3747d08e4531a7008f89ea/my_handler.py", line 20, in preprocess
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG -     return torch.as_tensor(nd, device=self.device)
2022-11-01T16:55:54,940 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - NameError: name 'nd' is not defined
2022-11-01T16:56:49,981 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T16:56:49,982 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]41508
2022-11-01T16:56:49,983 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T16:56:49,983 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T16:56:49,992 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T16:56:50,008 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T16:56:50,047 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T16:56:58,614 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667293018
2022-11-01T16:56:58,618 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [{'body': {'instances': [[[0.027652508954327904, 0.07238308265169527, 0.09864100395351688, 0.04425131509070399, 0.10793293031718294, 0.07389489307156828, 0.12064058423390212, 0.10187934183235252, 0.09341338949880844, 0.09527291863890545, 0.11822001940163833, 0.06415241774520729, 0.15985844033815738, 0.11248141394752291, 0.1075329862755908, 0.09917514315152125, 0.0818321139053955, 0.07239242430455653, 0.09363908460114258, 0.09836124685343056, 0.10574652454025393, 0.09890158523453704, 0.1526130124328318, 0.18719417731209193, 0.1885288047673577, 0.2261635980308232, 0.20786397945701818, 0.22838564967365854, 0.2255767041061822, 0.6137741860819624, 0.2010166356838014, 0.19345743860500403, 0.2037928853750772, 0.21149949796603382, 0.21474549163374973, 0.21787418281909796, 0.22443279357227164, 0.23782154771927536, 0.22467722336698673, 0.23225774100925323, 0.21204969043306857, 0.24363216673089402, 0.22757264661049215, 0.24997438878271716, 0.22984207126554634, 0.21612404691331488, 0.1954175423487311, 0.1470415511939073, 0.15017012637066354, 0.1282514113355846, 0.1600614562644808, 0.1954663974857656, 0.17255251210146152, 0.20583605379259814, 0.2022914616319765, 0.20896027369600179, 0.19472840856970897, 0.20303572560854818, 0.22362215012457645, 0.20771741296902121, 0.5625202893457166, 0.2255601393604278, 0.24650449948174763, 0.23919865832066547, 0.5842179092973283, 0.2535873789573413, 0.2534568779067799, 0.2457886644407459, 0.23949227935838685, 0.2510887644876215, 0.28886937492785214, 0.28636650322901824, 0.6726774679616399, 0.22696724726912332, 0.2111760995050743, 0.21229407064273903, 0.18612568449362893, 0.21008112690358186, 0.19068567873679085, 0.1751503401791556, 0.08944879709338445, 0.1097361187676429, 0.07699696987634731, 0.1368366355997489, 0.11287362751902351, 0.09091659907469825, 0.06589933582690254, 0.10360271952187153, 0.09765765328270329, 0.08350698932606214, 0.08663845849211646, 0.08560970897039663, 0.0818726482528911, 0.111095863369841, 0.10451426797720198, 0.091473974511811]], [[0.07108073214347084, 0.07855894518070233, 0.06871803347355863, 0.08053185008856067, 0.1462422795668576, 0.10377282358329833, 0.1375701632822184, 0.10965704229061109, 0.1793861461304077, 0.14193757128124643, 0.15430233928118328, 0.15774236617157142, 0.13547264511396734, 0.15580052199397382, 0.1077183006873966, 0.1476057013629621, 0.14801538304716075, 0.12830803214354036, 0.12468708885967782, 0.10896787178130425, 0.13627592006767075, 0.15156159297350683, 0.10579636244010451, 0.11813957172472592, 0.18893022865020964, 0.1979769982583465, 0.1325203730388171, 0.2182043335679129, 0.18524094886471942, 0.6143401280633585, 0.23855537395243484, 0.16313244819394923, 0.16088954645777656, 0.20024043891853513, 0.1959589414394306, 0.1578944390827772, 0.17027686107494994, 0.17803893888120773, 0.17338886817260743, 0.1984508200003811, 0.18517650347651377, 0.20541136893756534, 0.1850774397290474, 0.19477368285486088, 0.1659294503092899, 0.16635080536062455, 0.14417044218129288, 0.12884640912974046, 0.11512213543200275, 0.0853890998645376, 0.08749685076376013, 0.1469138822547218, 0.11635817283059051, 0.1668843599837598, 0.15482450214870982, 0.19738357353674774, 0.17124986554583446, 0.16253388654055692, 0.18336561288093003, 0.15788268244817885, 0.5286078827449375, 0.189298569680485, 0.19339474190412873, 0.18630948192430793, 0.5504771065455623, 0.18091753061482727, 0.22806193511390044, 0.19645263004975122, 0.199818382641865, 0.253321267114035, 0.30304718541136194, 0.26228270583167207, 0.6589699709085498, 0.20542577913085278, 0.1904728331471315, 0.14779533838920358, 0.18164114427396158, 0.17409439651117384, 0.09565996673792566, 0.13812939257401974, 0.0932176198326777, 0.10944649619562609, 0.06365877624419974, 0.09266602679154831, 0.07515209741831146, 0.035529825533945604, 0.06567972260648676, 0.053655801312592594, 0.058493008804908424, 0.06400640696957396, 0.10486689176410674, 0.040831139183156194, 0.024881588381710163, 0.08073079976956364, 0.039142647377853695, 0.11545730583288337]]]}}]
2022-11-01T16:56:58,684 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model: loading-prediction, number of batch response mismatched, expect: 1, got: 2.
2022-11-01T17:06:06,549 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-11-01T17:06:06,550 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - [PID]42090
2022-11-01T17:06:06,550 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Torch worker started.
2022-11-01T17:06:06,550 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Python runtime: 3.6.5
2022-11-01T17:06:06,561 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-11-01T17:06:06,576 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - model_name: loading-prediction, batchSize: 1
2022-11-01T17:06:06,615 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-11-01T17:06:12,984 [INFO ] W-9000-loading-prediction_1.0-stdout MODEL_LOG - Backend received inference at: 1667293572
