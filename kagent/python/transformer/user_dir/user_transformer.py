#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from typing import List, Dict
import logging
import kserve
import http.client
import json
import numpy as np
import pandas as pd
import datetime

UNKNOWN_TOKEN = 'UNK'
#raw data columns
RAW_COLUMN_NAME = ['timestamp', 'Current_Phase_Average', 'Weather_Temperature_Celsius', 'Weather_Relative_Humidity',\
        'Global_Horizontal_Radiation', 'Diffuse_Horizontal_Radiation', 'Wind_Direction', 'Weather_Daily_Rainfall']


def Singleton(cls):
    _instance = {}
    def _singleton(*args, **kwargs):
        if cls not in _instance:
            _instance[cls] = cls(*args, **kwargs)
        return _instance[cls]
    return _singleton

@Singleton
class MyTransformer(object):
    """
    user defined transformer
    This is an example.
    Preprocess and postprocess are required methods.
    This class will be used in such way:
    1. framework instantiate this class.
        in this step,user usually do some preparation work(e.g.,load global configuration).
    2. framework call preprocess method on instance mentioned above.
    3. framework request predictor with result of step2.
    4. framework call postprocess method on instance of step1 and pass result of step3 to postprocess.
    """
    def __init__(self, context: Dict):
        """
        initialize a instance

        Args:
            context: environment variables passed by caller
        """
        # data_path point to outer data path
        data_path = context['data_path']
        # feature_type.txt and feature_value.txt are generated by user
        fea_type_file = os.path.join(data_path, 'feature_type.txt')
        fea_value_file = os.path.join(data_path, 'feature_value.txt')
        # list of feature type pair
        self.fea_type = self.load_feature_type(fea_type_file)
        # dict of feature values pair
        self.fea_value = self.load_feature_value(fea_value_file)
        #print('feature type size: %d' % len(self.fea_type))
        #print('feature value size: %d' % len(self.fea_value))

    def preprocess(self, inputs: Dict):
        """
        Args:
            inputs (Dict): input data
        """
        result_data = {'instances': []}
        if not 'instances' in inputs:
            return result_data
        input_data = inputs['instances']
        for data in input_data:
            res = self.feature_work(data, RAW_COLUMN_NAME, self.fea_type, self.fea_value)
            if res:
                result_data['instances'].append(res)
        #logging.info("The input for model predict is %s", result_data)
        return result_data

    def feature_work(self, raw_data: List, cols_name: List, type_info: List, value_info: Dict):
        res = []
        md = {}
        for n,v in zip(cols_name, raw_data):
            md[n] = v
        # 特征抽取
        if 'timestamp' in md:
            ts = md['timestamp']
            date_info = datetime.datetime.strptime(ts, '%Y-%m-%d %H:%M:%S')
            md['Month'] = date_info.month
            md['Day'] = date_info.day
            md['Day_Of_Week'] = date_info.weekday()
            md['Hour'] = date_info.hour
        else:
            md['Month'] = UNKNOWN_TOKEN
            md['Day'] = UNKNOWN_TOKEN
            md['Day_Of_Week'] = UNKNOWN_TOKEN
            md['Hour'] = UNKNOWN_TOKEN
        print('features:', md)
        print('feature list:', type_info)
        # 特征变换
        for f,t in type_info:
            values = value_info[f]
            if t == 'category':
                if f in md and md[f] and str(md[f]) in values:
                    res.append(values[str(md[f])])
                else:
                    res.append(values[UNKNOWN_TOKEN])
            elif t == 'numeric':
                mean = float(values['mean'])
                std = float(values['std'])
                if f in md and f in ['Weather_Temperature_Celsius', 'Weather_Relative_Humidity', \
                        'Global_Horizontal_Radiation', 'Diffuse_Horizontal_Radiation']: # 标准化
                    if std > 0:
                        res.append((float(md[f])-mean)/std)
                    else:
                        res.append(float(md[f]))
                elif f in md: # 使用原数值
                    res.append(float(md[f]))
                else: # 缺失值使用均值填充
                    res.append(mean)
        print('converted features:', res)
        return res

    def load_feature_value(self, feature_value_file: str):
        """
        features_value_file: 特征统计信息
        返回字典:
        {
            feature1: {min:0, max:0, mean:0, std:0}, # 数值特征，用户自定义的统计量
            feature2: {v1:0, v2:1} # 类别特征，枚举所有取值
        }
        """
        fea_info = {}
        with open(feature_value_file, 'r') as file1:
            for line in file1:
                # name type values
                vs = line.strip('\r\n').split('\t')
                dv = json.loads(vs[2])
                if vs[1] == 'category':
                    if ('values' in dv) and dv['values'] and type(dv['values']) == list: # dv is a dict, it contains key 'values', whose value is a list
                        md = {}
                        for i,v in enumerate(dv['values']):
                            if not v in md:
                                md[v] = i
                        fea_info[vs[0]] = md
                    elif 'from_file' in dv and dv['from_file'] and type(dv['from_file']) == 'str':
                        md = load_category_values(dv['from_file'])
                        fea_info[vs[0]] = md
                elif vs[1] == 'numeric' and dv: # dv is a dict, for example: {mean:0, std:0,...}
                    fea_info[vs[0]] = dv
        return fea_info

    def load_feature_type(self, feature_type_file: str):
        """
        feature_type_file: 特征序列
        返回二维数组[[feature, type]]
        """
        fea_type = []
        with open(feature_type_file, 'r') as file1:
            for line in file1:
                # name type
                vs = line.strip('\r\n').split('\t')
                fea_type.append((vs[0], vs[1]))
        return fea_type

    def postprocess(self, inputs: Dict) -> Dict:
        logging.info("The output from model predict is %s", inputs)
        '''
        if self.protocol == "grpc-v2":
            response = InferResult(inputs)
            return response.get_response(as_json=True)
        elif self.protocol == "http":
            pass
        '''
        return inputs


def preprocess(inputs: Dict, data_path: str):
    processor = MyTransformer({'data_path': data_path})
    return processor.preprocess(inputs)

def postprocess(inputs: Dict, data_path: str):
    processor = MyTransformer({'data_path': data_path})
    return processor.postprocess(inputs)

def batch_preprocess(df: pd.DataFrame, data_path: str):
    pass

def batch_postprocess(df: pd.DataFrame, data_path: str):
    pass

